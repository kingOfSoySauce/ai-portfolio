选 **2（Python 主线）**很稳：岗位覆盖更大、生态更贴近“LLM 应用/Agent/RAG 工程”默认预期。下面我把你那份 **14 天试运行**细化成「每天要写哪些文件、做哪些接口、怎么跑、验收截图清单」，你照着做就能交付。

> 目标不变：**RAG + 工具调用 + 前端界面 + 工程化（失败策略/日志/评估/面试卡片）**
> 时间预算：工作日 1–1.5h，周末 4–5h

---

# 统一技术栈（别纠结，先跑起来）

* **后端**：FastAPI + Uvicorn + Pydantic
* **向量库**：FAISS（本地）
* **Embedding**：优先本地 `sentence-transformers`（不依赖 Key）；可选接 OpenAI
* **前端**：先用 `HTML + JS`（支持 SSE 流式）→ 后面再美化
* **工程化**：超时/重试/降级、请求日志、简单评估脚本

--
# 环境与启动命令（你每次都用这一套）

```bash
cd backend
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000
# API 文档：http://localhost:8000/docs
```

前端：

```bash
cd frontend
python -m http.server 5173
# 页面：http://localhost:5173
```

---

# requirements.txt（建议 Day1 直接填）

最小可用集（先跑通）：

```txt
fastapi
uvicorn[standard]
pydantic
python-multipart
httpx
faiss-cpu
sentence-transformers
numpy
pypdf
```

> 你如果要接 OpenAI，再加 `openai`（但不是必须）

---

# Day-by-Day：14 天交付清单（含文件/接口/验收）

## Day 1：工程骨架（最重要）

**做什么**

* 初始化 repo + 目录结构
* FastAPI 起一个健康检查接口

**你要写的文件**

* `backend/app/main.py`：挂载 router、CORS、/health
* `backend/app/core/config.py`：读环境变量（如模型模式、本地/远程）
* `backend/app/core/logging.py`：基础日志（请求耗时）

**接口**

* `GET /health` → `{ "ok": true }`

**验收截图**

* `/docs` 能打开
* `/health` 返回 ok

---

## Day 2：LLM 调用 + SSE 流式输出（前端优势位）

**做什么**

* 做一个最小聊天页，支持流式输出（SSE）

**你要写的文件**

* `backend/app/api/chat.py`：`POST /chat/stream`（SSE）
* `frontend/index.html` + `frontend/app.js`：消费 SSE

**接口**

* `POST /chat/stream`
  输入：`{ "message": "你好", "session_id": "xxx" }`
  输出：SSE event，逐段推送 `delta`

**实现建议**

* 先用“假 LLM”（把输入拆字吐出去）跑通 SSE
* 后面再替换真实 LLM client（减少卡壳）

**验收**

* 浏览器页面能看到“逐字输出”

---

## Day 3：结构化输出（JSON Schema / Pydantic 校验）

**做什么**

* 做一个“信息抽取”接口：输入文本 → 输出结构化 JSON（并能校验失败重试）

**文件**

* `backend/app/api/extract.py`
* 定义 Pydantic Model，例如：

  * `TaskExtract { intent: str, entities: dict, confidence: float }`

**接口**

* `POST /extract`
  输入：`{ "text": "帮我查一下明天北京天气" }`
  输出：`{ intent: "...", entities: {...}, confidence: 0.82 }`

**验收**

* 给 5 条样例文本都能稳定输出合法 JSON（不合法就重试/兜底）

---

## Day 4：Embedding + 本地向量库（RAG 的骨头）

**做什么**

* 文本切块 → embedding → FAISS 入库 → top-k 检索

**文件**

* `backend/app/rag/chunker.py`（chunk_size/overlap）
* `backend/app/rag/embeddings.py`（sentence-transformers）
* `backend/app/rag/vectorstore.py`（FAISS 保存/加载）
* `backend/app/api/ingest.py`（先做一个“文本入库”接口）

**接口**

* `POST /ingest/text`
  输入：`{ "doc_id": "a", "text": "..." }`

* `GET /rag/search?q=...`
  输出：top-k chunks（带 doc_id、chunk_id、score）

**验收**

* 能检索到你放进去的内容（返回 chunk + score）

---

## Day 5：最小 RAG（检索→拼接→回答，强制引用）

**做什么**

* 用检索结果拼接上下文，让模型回答，并**强制带引用**

**文件**

* `backend/app/api/rag.py`：`POST /rag/answer`
* `backend/app/rag/prompts.py`：包含引用格式约束
* `backend/app/rag/qa.py`：组装 prompt + 生成回答

**接口**

* `POST /rag/answer`
  输入：`{ "question": "...", "top_k": 4 }`
  输出：

  ```json
  {
    "answer": "...",
    "citations": [
      {"doc_id":"a","chunk_id":3,"quote":"..."}
    ]
  }
  ```

**验收**

* 没有检索结果时：必须触发“信息不足/建议上传文档”的回答（拒答/追问）

---

## Day 6（周末）：做成“产品壳”——上传文档入库 + 前端展示引用

**做什么**

* 支持上传 1–3 个文档（txt/md/pdf）并入库
* 前端展示引用列表（点击可展开引用）

**文件**

* `backend/app/api/ingest.py`：`POST /ingest/upload`
* `frontend/app.js`：加上传/问答 UI

**接口**

* `POST /ingest/upload`（multipart）
* `POST /rag/answer`

**验收**

* 上传 PDF/MD 后能问出答案，且 citations 可点击查看 quote

---

## Day 7（周末）：README v0.1 + 录屏 30 秒

**做什么**

* README 写清楚：目标、架构、启动方式、示例、截图
* 录屏（只要能展示：上传 → 提问 → 有引用）

**文件**

* `README.md`（根目录）
* 可加 `docs/architecture.png`（手画也行）

**验收**

* README 看起来像一个能被面试官快速理解的项目主页

---

## Day 8：工具调用（Tool）——让系统“会做事”

**做什么**

* 加一个工具：计算器（最简单、最稳）

**文件**

* `backend/app/tools/registry.py`（工具注册）
* `backend/app/tools/calculator.py`
* `backend/app/api/chat.py`：在聊天流里支持 tool 调用 & 日志

**接口行为**

* 用户说：“计算 19*23” → 模型/规则触发调用 calculator → 返回结果 → 再组织自然语言回答
  （先用规则触发也行，后续再升级为真正的 tool-calling）

**验收**

* 前端能看到“调用了哪个工具、参数是什么、结果是什么”

---

## Day 9：失败策略（你像不像工程师，就看这天）

**做什么**

* 超时/重试/降级
* 检索不到的处理（追问/扩大 top-k/提示上传）
* 低置信度时：回答必须保守 + 明确引用不足

**文件**

* `backend/app/rag/qa.py`：加阈值策略
* `backend/app/api/rag.py`：统一错误码

**验收**

* 人为制造失败（空库/无关问题/超时）系统不会崩，且输出可解释

---

## Day 10：成本与日志（面试加分项）

**做什么**

* 记录：耗时、top_k、命中数、是否触发降级、（可选）token 估算
* 做一个 `/stats` 接口返回最近 N 次请求的指标

**文件**

* `backend/app/core/logging.py`：request middleware
* `backend/app/api/rag.py`：写入日志（jsonl 或 sqlite 都行）

**接口**

* `GET /stats/recent`

**验收**

* 你能回答面试官：一次请求大概多慢、哪些步骤最慢、怎么优化

---

## Day 11：评估最小集（20 条 QA + 自动跑）

**做什么**

* 准备一个 `dataset.jsonl`（20 条）
* 写 `run_eval.py` 自动请求 `/rag/answer`
* 输出报告：引用覆盖率、空引用率、平均耗时

**文件**

* `backend/app/eval/dataset.jsonl`
* `backend/app/eval/run_eval.py`

**验收**

* 一条命令跑完 eval，并生成 `report.json`

---

## Day 12（周末）：UI/交互打磨（你的“作品集气质”从这来）

**做什么**

* 引用高亮、对话回放、检索调试面板（显示 top-k chunks）
* 增加一个“Debug 开关”：展示检索结果/分数

**验收**

* Demo 看起来像产品，而不是接口集合

---

## Day 13（周末）：10 张面试问答卡片（直接能背）

**文件**

* `notes/interview-cards.md`

给你 10 个必写题目（每题 30 秒口述版）：

1. 为什么要 chunk？chunk size 怎么选？
2. 检索不到怎么办？（追问/扩大召回/提示上传）
3. 如何降低幻觉？（引用强制 + 不足拒答 + 自检）
4. top-k 取多少？为什么？
5. 为什么需要重排/多查询？你实现了吗？
6. Agent/工具调用怎么做？失败怎么处理？
7. 你怎么做评估？指标是什么？如何回归？
8. 你怎么控制成本和延迟？
9. 你的系统有哪些已知局限？下一步怎么做？
10. 如果上生产，你会加什么监控/限流/权限？

---

## Day 14：最终整理 + 简历一句话版本 + release tag

**做什么**

* README v1.0（补：设计决策、失败策略、评估结果）
* 打 tag：`v1.0.0`
* 写简历 bullet（下面给你模板）

**简历一句话模板（可直接用）**

> 基于 FastAPI + FAISS 构建企业知识库 RAG 应用，支持文档上传入库、向量检索与引用溯源、工具调用（calculator）、失败降级（检索缺失追问/拒答）、请求日志与最小评估集（20 条 QA 自动回归），并提供前端可视化（SSE 流式 + 引用高亮 + debug 检索面板）。

---

# 你每天都要拍的“证据清单”（防止学着学着虚了）

* Day2：流式输出录屏
* Day5：引用回答截图
* Day6：上传 PDF → 问答录屏
* Day9：失败策略演示（空库/无关问题仍稳定输出）
* Day11：eval 报告截图
* Day14：README 首页截图 + 目录结构截图

---

# 关键提醒：Python 主线不等于“先学一堆 Python”

你不用先把并发/八股啃完。你按上面 14 天做项目，过程中你自然会学到：

* async/await、超时重试（Day9）
* SSE/WebSocket（Day2）
* 性能与监控（Day10）

这比纯看课快太多。

---

## 你现在只要回我 2 个信息，我就把 Day1～Day3 细化到“可直接复制的代码骨架”

1. 你打算 **接 OpenAI API** 还是 **全本地模型**（Ollama 之类）？
2. 你的开发环境是 macOS 吗（看起来是），是否介意装 `faiss-cpu` / `sentence-transformers` 这些依赖？

你回完我就把 **Day1～Day3 的具体代码文件内容**（main.py、chat SSE、extract JSON 校验）直接给你，保证一小时内跑通。
